
model_method_A_sign_0_tau_1_wn_False_ws_False
Epoch:   0%|                                                                                                | 0/50 [00:00<?, ?it/s]
 Train acc 0.262, Train loss 0.015169




Epoch:   8%|███████                                                                                 | 4/50 [04:47<54:54, 71.62s/it]
 Train acc 0.388, Train loss 0.012850

Epoch:  10%|████████▊                                                                               | 5/50 [06:32<58:56, 78.59s/it]
Traceback (most recent call last):
  File "/home/aengusl/jean72human/transformers-as-gradient-flow/exp_cifar.py", line 91, in <module>
    train_loss, train_acc = train(model,train_loader,optimizer,criterion,epoch,device)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aengusl/jean72human/transformers-as-gradient-flow/utils.py", line 21, in train
    loss.backward()
  File "/home/aengusl/anaconda3/envs/tgf73/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/aengusl/anaconda3/envs/tgf73/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt