
model_method_PME_sign_0_tau_1_wn_False_ws_False
Epoch:   0%|                                                                                | 0/50 [00:00<?, ?it/s]
 Train acc 0.154, Train loss 0.017572



Epoch:   6%|████▏                                                                | 3/50 [06:07<1:36:03, 122.63s/it]
Traceback (most recent call last):
  File "/home/aengusl/jean72human/transformers-as-gradient-flow/exp_cifar.py", line 97, in <module>
    train_loss, train_acc = train(model,train_loader,optimizer,criterion,epoch,device)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aengusl/jean72human/transformers-as-gradient-flow/utils.py", line 21, in train
    loss.backward()
  File "/home/aengusl/anaconda3/envs/tgf73/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/aengusl/anaconda3/envs/tgf73/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt