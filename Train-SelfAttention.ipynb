{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c70c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import train, plot_images_full, generate_matrix, batch_dirichlet, get_similarities, plot_similarities, get_differences, plot_differences, get_images, plot_images\n",
    "\n",
    "from models.vit_old import ViT\n",
    "from models.diffusion import SimpleTransformer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_one.pth\"\n",
    "batch_size = 64\n",
    "size = (3,32,32)\n",
    "patch_size = 2\n",
    "depth = 64\n",
    "device = 'cuda:0'\n",
    "data_path = './data/'\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34dbdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f294a",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abaeb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTransformer(size, patch_size, depth, \n",
    "                          dim=128, \n",
    "                          heads=1,\n",
    "                          num_classes=10, \n",
    "                          sign=-1, \n",
    "                          tau=1, \n",
    "                          embed=True,\n",
    "                          softw=False,\n",
    "                          weight_sharing=False, \n",
    "                          method='FT',\n",
    "                          norm=True,\n",
    "                          weight_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21aca9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViT(\n",
    "#     image_size = size[1],\n",
    "#     patch_size = patch_size,\n",
    "#     num_classes = 10,\n",
    "#     dim = 256,\n",
    "#     depth = depth,\n",
    "#     heads = 8,\n",
    "#     mlp_dim = 256,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1,\n",
    "#     pool = 'mean'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a410b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c7f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322ab7a48a4144ab96459b02cbe2e984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " Train acc 0.214, Train loss 0.032083\n",
      " Valid acc 0.232, Val loss 0.031481\n",
      "Epoch 2\n",
      " Train acc 0.243, Train loss 0.030778\n",
      " Valid acc 0.229, Val loss 0.031238\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_accs_list = []\n",
    "train_loss_list = []\n",
    "val_accs_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1), desc=\"Epoch\"):  \n",
    "    train_loss, train_acc = train(model,train_loader,optimizer,criterion,epoch,device)  \n",
    "\n",
    "    # Model validation\n",
    "    model.eval()\n",
    "    val_loss = val_acc = 0.0\n",
    "    for (img, labels) in val_loader:\n",
    "        img, labels = img.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(img)\n",
    "            loss = criterion(predictions, labels)\n",
    "            correct = torch.argmax(predictions.data, 1) == labels\n",
    "        val_loss += loss\n",
    "        val_acc += correct.sum()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    \n",
    "    train_accs_list.append(train_acc)\n",
    "    val_accs_list.append(val_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    \n",
    "    if (epoch%2==0) or epoch==num_epochs or epoch==1:\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\" Train acc {train_acc:.3f}, Train loss {train_loss:.6f}\")\n",
    "        print(f\" Valid acc {val_acc:.3f}, Val loss {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ae6297",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mdim\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c4e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba810088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d41b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_method_A_sign_-1_ws_True.pth'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m='A'\n",
    "s=-1\n",
    "ws=True\n",
    "f\"model_method_{m}_sign_{s}_ws_{ws}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1803386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(3.44444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88debc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B = torch.rand((64,64)),torch.rand((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1751a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B = torch.nn.functional.softmax(A,-1), B/torch.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15951ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0398)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f91566fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef8adcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9552)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(A+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169627b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
